{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b5c23d-3274-49ab-ba0f-c1e867a51487",
   "metadata": {},
   "source": [
    "## Code Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad46a15-c554-4d75-aed1-1a34f6ef1660",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1: Implement Decision Trees & 4.2: Implement a Random Forest\n",
    "#### this is done in decision_tree_starter.py & is available in code index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8b7c7-b912-499d-a0ea-91f204a36162",
   "metadata": {},
   "source": [
    "### 4.3: Describe implementation details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d4cea-dbd5-4323-9975-eb27b86c35c0",
   "metadata": {},
   "source": [
    "#### 1. For categorical features I used one hot encoding to get binary values and for missing values I used the mode of column \n",
    "#### 2. Stopping criterion was based on the depth I wanted the tree to go. \n",
    "#### 3. By making/using the decision tree class in decision_tree_starter.py and train the decision trees with m random features and sampling with replacement. \n",
    "#### 4. Other than removing unnecessary features or experimentings with depth levels, I did not. \n",
    "#### 5. Random forest perhaps since its only one that works. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41cec1a-3131-4809-bbc9-467c18f8ff2f",
   "metadata": {},
   "source": [
    "### 4.4 Performance Evaluation\n",
    "#### Kaggle Username: Jose Fernandez\n",
    "#### Kaggle Spam Score: 0.735\n",
    "#### Kaggle Titanic Score: N/A\n",
    "#### below are the accuracy scores for the spam and titanic datasets(4 spam scores & 2 titanic scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f0df4c1e-5991-4797-a13e-ec2f79113e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import sklearn.model_selection\n",
    "import sklearn.tree\n",
    "from numpy import genfromtxt\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import decision_tree_starter\n",
    "eps = 1e-5 # a small number\n",
    "def most_frequent(List):\n",
    "    dict = {}\n",
    "    count, itm = 0, ''\n",
    "    for item in reversed(List):\n",
    "        if not item:\n",
    "            pass\n",
    "    dict[item] = dict.get(item, 0) + 1\n",
    "    if dict[item] >= count :\n",
    "        count, itm = dict[item], item\n",
    "    return(itm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d587684b-0a4f-45bc-a274-d94261720a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Spam Train: (5629, 32)\n",
      "Shape of Spam Train Labels: (5629,)\n",
      "Shape of Spam Test: (5400, 32)\n",
      "Shape of Titanic Train: (1010, 10)\n",
      "Shape of Titanic Labels: (301, 9)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "spam_data = scipy.io.loadmat(\"/Users/jose/Downloads/hw5/datasets/spam_data/spam_data.mat\")\n",
    "spam_train_data = spam_data['training_data']\n",
    "spam_train_labels = spam_data['training_labels'].flatten()\n",
    "spam_test_data = spam_data['test_data']\n",
    "titanic_train_data = genfromtxt(\"/Users/jose/Downloads/hw5/datasets/titanic/titanic_training.csv\",\n",
    "    delimiter=',')\n",
    "titanic_test_data = genfromtxt(\"/Users/jose/Downloads/hw5/datasets/titanic/titanic_testing_data.csv\",\n",
    "delimiter=',')\n",
    "S_train, S_test, SY_train, SY_test = train_test_split(spam_train_data,\n",
    "    spam_train_labels, test_size=0.2)\n",
    "# shape of datasets\n",
    "print(f\"Shape of Spam Train: {spam_train_data.shape}\")\n",
    "print(f\"Shape of Spam Train Labels: {spam_train_labels.shape}\")\n",
    "print(f\"Shape of Spam Test: {spam_test_data.shape}\")\n",
    "print(f\"Shape of Titanic Train: {titanic_train_data.shape}\")\n",
    "print(f\"Shape of Titanic Labels: {titanic_test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "93ad6f17-a74b-4896-a295-f69fda104bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training accuracy for the Spam Training dataset is:0.7257383966244726\n",
      "Our training accuracy for the Spam Testing dataset is:0.7291296625222025\n"
     ]
    }
   ],
   "source": [
    "# classify Spam.\n",
    "spam_features = [\n",
    "           \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\",\n",
    "               \"creative\",\n",
    "\"height\", \"featured\", \"differ\", \"width\", \"other\", \"energy\",\n",
    "               \"business\", \"message\",\n",
    "           \"buy\", \"click here\", \"instant\", \"limited time\", \"100%\", \"access\",\n",
    "               \"guarantee\",\n",
    "           \"offer\", \"re:\", \"<head>\", \"<title>\", \"<body>\", \"<html>\", \"#\", \"&\", \"volumes\", \"revision\", \"path\",\n",
    "            \"memo\", \"planning\", \"pleased\", \"record\", \"out\"\n",
    "            ]\n",
    "spam_tree = DecisionTree(max_depth = 5, feature_labels = spam_features)\n",
    "# fitting, predicting, and evaluation.\n",
    "spam_tree.fit(S_train, SY_train)\n",
    "spam_predictions = spam_tree.predict(S_train)\n",
    "spam_predictions_Y = spam_tree.predict(S_test)\n",
    "spam_train_accuracy = sum(spam_predictions == SY_train) / len(spam_predictions)\n",
    "spam_train_accuracy_Y = sum(spam_predictions_Y == SY_test) / len(spam_predictions_Y)\n",
    "print(f\"Our training accuracy for the Spam Training dataset is:{spam_train_accuracy}\")\n",
    "print(f\"Our training accuracy for the Spam Testing dataset is:{spam_train_accuracy_Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "80d4cb2e-4104-4245-85d1-e1ba101e332b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training accuracy for the Spam Training dataset using Random Forests is: 0.7255163224516988\n",
      "Our training accuracy for the Spam Testing dataset using Random Forests is: 0.7291296625222025\n"
     ]
    }
   ],
   "source": [
    "# classify Spam using Random Forests.\n",
    "params = {\"max_depth\": 2,\n",
    "         \"feature_labels\": spam_features}\n",
    "spam_tree_RF = RandomForest(params=params, m=2, n=200)\n",
    "# No need to split. Proceed with fitting, predicting, and evaluation.\n",
    "spam_tree_RF.fit(S_train, SY_train)\n",
    "spam_predictions_RF = spam_tree_RF.predict(S_train)\n",
    "spam_predictions_RF_Y = spam_tree_RF.predict(S_test)\n",
    "spam_train_accuracy_RF = sum(spam_predictions_RF == SY_train) / len(spam_predictions_RF)\n",
    "spam_train_accuracy_RF_Y = sum(spam_predictions_RF_Y == SY_test) / len(spam_predictions_RF_Y)\n",
    "print(f\"Our training accuracy for the Spam Training dataset using Random Forests is: {spam_train_accuracy_RF}\")\n",
    "print(f\"Our training accuracy for the Spam Testing dataset using Random Forests is: {spam_train_accuracy_RF_Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "02677309-b10d-46fb-8212-30f483a82808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classify the Titanic Dataset.\n",
    "# preprocessing automatically.\n",
    "def preprocessingTitanic(data, train=True):\n",
    "    if train:\n",
    "        # Convert to df.\n",
    "        df_columns = [\"embarked\", \"cabin\", \"fare\", \"ticket\", \"parch\", \"sibsp\",\"sex\", \"age\", \"pclass\", \"survived\"]\n",
    "        df = pd.DataFrame(data, columns = df_columns)\n",
    "        # Handle NaN values. Remove columns with entirely NaN values. Replace others with mode’s of the column.\n",
    "        MMM = np.array([])\n",
    "        for i in df_columns:\n",
    "            MMM = np.append(MMM, most_frequent(df[i].to_numpy()))\n",
    "        df = df.drop([\"cabin\", \"age\", \"pclass\"], axis=1)\n",
    "        surviving_columns = [\"embarked\", \"fare\", \"ticket\", \"parch\", \"sibsp\",\n",
    "        \"sex\", \"survived\"]\n",
    "        MMM = np.delete(np.delete((np.delete(MMM, 1)), 6), 6)\n",
    "        for i, col in enumerate(surviving_columns):\n",
    "            df[col] = df[col].fillna(MMM[i])\n",
    "        # Convert back to column, return training and labels\n",
    "        return df[[\"embarked\", \"fare\", \"ticket\", \"parch\", \"sibsp\", \"sex\"]].to_numpy(), df[[\"survived\"]].to_numpy()\n",
    "    else:\n",
    "        # Convert to df.\n",
    "        df_columns = [\"embarked\", \"cabin\", \"fare\", \"ticket\", \"parch\", \"sibsp\",\"sex\", \"age\", \"pclass\"]\n",
    "        df = pd.DataFrame(data, columns = df_columns)\n",
    "        # Handle NaN values. Remove columns with entirely NaN values. Replace others with mode’s of the column.\n",
    "        MMM = np.array([])\n",
    "        for i in df_columns:\n",
    "            MMM = np.append(MMM, most_frequent(df[i].to_numpy()))\n",
    "        df = df.drop([\"cabin\", \"age\", \"pclass\"], axis=1)\n",
    "        surviving_columns = [\"embarked\", \"fare\", \"ticket\", \"parch\", \"sibsp\", \"sex\"]\n",
    "        MMM = np.delete(np.delete((np.delete(MMM, 1)), 6), 6)\n",
    "        for i, col in enumerate(surviving_columns):\n",
    "            df[col] = df[col].fillna(MMM[i])\n",
    "        # Convert back to column\n",
    "        return df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1c15e6ee-fe46-4b48-b6be-d69afc68791a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# process both of our datasets.\n",
    "titanic_train_data, titanic_train_labels = preprocessingTitanic(titanic_train_data, True)\n",
    "titanic_test_data = preprocessingTitanic(titanic_test_data, False)\n",
    "titanic_train_labels = titanic_train_labels.flatten()\n",
    "T_train, T_test, TY_train, TY_test = train_test_split(titanic_train_data, titanic_train_labels, test_size=0.2)\n",
    "# Next, we fit these datasets to our model.\n",
    "titanic_features = [\"embarked\", \"fare\", \"ticket\", \"parch\", \"sibsp\", \"sex\"]\n",
    "titanic_tree = DecisionTree(max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "77beca42-5926-431c-bb38-7a3488a47139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training accuracy for the Titanic Training dataset is:0.0\n",
      "Our training accuracy for the Titanic Testing dataset is: 0.0\n"
     ]
    }
   ],
   "source": [
    "# fitting, predicting, and evaluation.\n",
    "titanic_tree.fit(T_train, TY_train)\n",
    "titanic_predictions = titanic_tree.predict(T_train)\n",
    "titanic_predictions_Y = titanic_tree.predict(T_test)\n",
    "titanic_train_accuracy = sum(titanic_predictions == TY_train) /len(titanic_predictions)\n",
    "titanic_train_accuracy_Y = sum(titanic_predictions_Y == TY_test) /len(titanic_predictions_Y)\n",
    "print(f\"Our training accuracy for the Titanic Training dataset is:{titanic_train_accuracy}\")\n",
    "print(f\"Our training accuracy for the Titanic Testing dataset is: {titanic_train_accuracy_Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9837a585-6ae4-41a1-ba95-4b841bf874d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DecisionTreeClassifier.__init__() got an unexpected keyword argument 'feature_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[234], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Random forests classifier to examine Titanic dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m titanic_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m: titanic_features}\n\u001b[0;32m----> 4\u001b[0m titanic_tree_RF \u001b[38;5;241m=\u001b[39m decision_tree_starter\u001b[38;5;241m.\u001b[39mRandomForest(params\u001b[38;5;241m=\u001b[39mtitanic_params, m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      5\u001b[0m     n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# fitting, predicting, and evaluation.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m titanic_tree_RF\u001b[38;5;241m.\u001b[39mfit(T_train, TY_train)\n",
      "File \u001b[0;32m~/Downloads/hw5/decision_tree_starter.py:148\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, params, n, m)\u001b[0m\n\u001b[1;32m    146\u001b[0m def predict(self, X):\n\u001b[1;32m    147\u001b[0m     # TODO\n\u001b[0;32m--> 148\u001b[0m     pass\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \n",
      "File \u001b[0;32m~/Downloads/hw5/decision_tree_starter.py:127\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, params, n)\u001b[0m\n\u001b[1;32m    125\u001b[0m return \"[%s < %s: %s | %s]\" % (self.features[self.split_idx],\n\u001b[1;32m    126\u001b[0m                                self.thresh, self.left.__repr__(),\n\u001b[0;32m--> 127\u001b[0m                                self.right.__repr__())\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m \n",
      "File \u001b[0;32m~/Downloads/hw5/decision_tree_starter.py:128\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m                                            self.thresh, self.left.__repr__(),\n\u001b[1;32m    127\u001b[0m                                            self.right.__repr__())\n\u001b[0;32m--> 128\u001b[0m \n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m class BaggedTrees(BaseEstimator, ClassifierMixin):\n",
      "\u001b[0;31mTypeError\u001b[0m: DecisionTreeClassifier.__init__() got an unexpected keyword argument 'feature_labels'"
     ]
    }
   ],
   "source": [
    "# Random forests classifier to examine Titanic dataset\n",
    "titanic_params = {\"max_depth\": 2,\n",
    "\"feature_labels\": titanic_features}\n",
    "titanic_tree_RF = decision_tree_starter.RandomForest(params=titanic_params, m=2,\n",
    "    n=200)\n",
    "# fitting, predicting, and evaluation.\n",
    "titanic_tree_RF.fit(T_train, TY_train)\n",
    "titanic_predictions_RF = titanic_tree_RF.predict(T_train)\n",
    "titanic_predictions_RF_Y = titanic_tree_RF.predict(T_test)\n",
    "titanic_train_accuracy_RF = sum(titanic_predictions_RF == TY_train) /len(titanic_predictions_RF)\n",
    "titanic_train_accuracy_RF_Y = sum(titanic_predictions_RF_Y == TY_test) /len(titanic_predictions_RF_Y)\n",
    "print(f\"Our training accuracy for the Titanic Training dataset using Random Forests is: {titanic_train_accuracy_RF}\")\n",
    "print(f\"Our training accuracy for the Titanic Testing dataset using Random Forests is: {titanic_train_accuracy_RF_Y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "00a218fa-1fd8-49e4-bffe-97b2119ed03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Kaggle Predictions\n",
    "def results_to_csv(file, name):\n",
    "    file = file.astype(int)\n",
    "    df = pd.DataFrame({'Category': file})\n",
    "    df.index += 1\n",
    "    df.to_csv(name, index_label=\"Id\")\n",
    "\n",
    "final_spam_prediction = spam_tree_RF.predict(spam_test_data)\n",
    "results_to_csv(final_spam_prediction, \"spam_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c777954-dea4-44a7-9714-a688c4137ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_titanic_prediction = titanic_tree_RF.predict(titanic_test_data)\n",
    "results_to_csv(final_titanic_prediction, \"titanic_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ae7bc-2bfe-4b5c-b5d2-71d77373a916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
